<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="QuantVLA: Quantizing Vision-Language-Action Models for efficient robot learning.">
  <meta name="keywords" content="QuantVLA, Robotics, VLA, Quantization">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>QuantVLA: Quantizing Vision-Language-Action Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./image/icon.jpg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <img src="./image/icon.jpg" alt="Icon" style="vertical-align: middle; height: 100px; margin-right: 10px;">
              <span style="font-size: 4rem; font-weight: bold; vertical-align: middle;">QuantVLA:</span>
              <br>
              <span class="is-size-2">Scale-Calibrated Post-Training Quantization for <br> Vision-Language-Action
                Models</span>
            </h1>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="#">Mi Zhang</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>The Ohio State University</span>
            </div>

            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-widescreen">
      <div class="hero-body">
        <div class="columns is-centered is-multiline">
          <div class="column is-one-quarter">
            <video autoplay muted loop playsinline style="width: 300px; height: auto; border-radius: 10px;">
              <source src="./video/simulation1.mp4" type="video/mp4">
            </video>
          </div>
          <div class="column is-one-quarter">
            <video autoplay muted loop playsinline style="width: 300px; height: auto; border-radius: 10px;">
              <source src="./video/simluation2.mp4" type="video/mp4">
            </video>
          </div>
          <div class="column is-one-quarter">
            <video autoplay muted loop playsinline style="width: 300px; height: auto; border-radius: 10px;">
              <source src="./video/simulation3.mp4" type="video/mp4">
            </video>
          </div>
          <div class="column is-one-quarter">
            <video autoplay muted loop playsinline style="width: 300px; height: auto; border-radius: 10px;">
              <source src="./video/simulation4.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">QuantVLA</span> enables efficient robot learning through quantization.
        </h2>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-12">
          <h2 class="title is-3">Abstract</h2>
          <div style="background-color: #f5f5f5; padding: 20px; border-radius: 10px;">
            <div class="content has-text-justified">
              <p>
                Vision-language-action (VLA) models unify perception, language, and control for embodied agents but face
                significant challenges in practical deployment due to rapidly increasing compute and memory demands,
                especially as models scale to longer horizons and larger backbones. To address these bottlenecks, we
                introduce <b>QuantVLA</b>, a training-free post-training quantization (PTQ) framework that, to our
                knowledge, is the first PTQ approach for VLA systems and the first to successfully quantize a diffusion
                transformer (DiT) action head. <b>QuantVLA</b> incorporates three scale-calibrated components: (1) a
                selective quantization layout that integerizes all linear layers in both the language backbone and the
                DiT
                while keeping attention projections in floating point to preserve the original operator schedule; (2)
                attention temperature matching, a lightweight per-head scaling mechanism that stabilizes attention
                logits
                and is folded into the dequantization scales at inference; and (3) output head balancing, a per-layer
                residual interface calibration that mitigates post-projection energy drift. The framework requires no
                additional training, uses only a small unlabeled calibration buffer, and supports integer kernels for
                low-bit weights and activations while leaving the architecture unchanged. Across representative VLA
                models
                on LIBERO, <b>QuantVLA</b> exceeds the task success rates of full-precision baselines, achieves about
                <b>70%</b> relative memory savings on the quantized components, and delivers a <b>1.22Ã—</b> speedup in
                end-to-end inference latency, providing a practical pathway toward scalable low-bit embodied
                intelligence
                under strict compute, memory, and power constraints.
              </p>

            </div>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Task Settings. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-12">
          <h2 class="title is-3">Task Settings</h2>
          <div class="content has-text-justified">
            <!-- Replace with your actual image path -->
            <img src="./image/task_example.png" alt="Task Settings" style="width: 100%; margin-bottom: 20px;">
            <p class="has-text-centered is-size-5">
              There is a total of 5 tasks in single franka arm setting.
            </p>
          </div>
        </div>
      </div>
      <!--/ Task Settings. -->

      <!-- Experiment. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-12">
          <h2 class="title is-3">Experiment</h2>
          <div class="content has-text-justified">
            <img src="./image/experiment1.png" alt="Experiment" style="width: 100%; margin-bottom: 20px;">
          </div>
        </div>
      </div>
      <!--/ Experiment. -->

      <!-- Paper video. -->
      <!-- <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div> -->
      <!--/ Paper video. -->
      <!-- </div>
  </section> -->


      <section class="section">
        <div class="container is-max-desktop">

          <div class="columns is-centered">
            <div class="column is-full-width">
              <h2 class="title is-3 has-text-centered">Method</h2>
              <div class="content has-text-justified">
                <p>
                  Qualitative and quantitative results demonstrating the efficiency and accuracy of QuantVLA will be
                  presented here.
                  The method relies on post-training quantization to reduce model size while maintaining VLA
                  capabilities.
                </p>
                <!-- Add Method diagram image here -->
                <img src="./image/pipeline1.svg" alt="Method Overview" style="width:100%">
              </div>
            </div>
          </div>

          <div class="columns is-centered">
            <div class="column is-full-width">
              <h2 class="title is-3">Results</h2>
              <div class="content has-text-justified">
                <p>
                  We compare QuantVLA against full-precision baselines on the Libero and OpenVLA benchmarks.
                </p>
                <!-- Add Results table/image here -->
              </div>
            </div>
          </div>


          <!-- Concurrent Work. -->
          <div class="columns is-centered">
            <div class="column is-full-width">
              <h2 class="title is-3">Related Links</h2>

              <div class="content has-text-justified">
                <p>
                  There's a lot of excellent work that was introduced around the same time as ours.
                </p>
                <p>
                <p>
                  We build upon recent advances in Vision-Language Models (VLMs) and Model Quantization.
                  Relevant works include OpenVLA, RT-2, and various post-training quantization methods.
                </p>
              </div>
            </div>
          </div>
          <!--/ Concurrent Work. -->

        </div>
      </section>


      <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
          <h2 class="title">BibTeX</h2>
          <pre><code>@article{quantvla2026,
  author    = {Anonymous},
  title     = {QuantVLA: Quantizing Vision-Language-Action Models},
  journal   = {CVPR Submission},
  year      = {2026},
}</code></pre>
        </div>
      </section>


      <footer class="footer">
        <div class="container">
          <div class="content has-text-centered">
            <a class="icon-link" href="#" class="external-link" disabled>
              <i class="fas fa-file-pdf"></i>
            </a>
            <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
              <i class="fab fa-github"></i>
            </a>
          </div>
          <div class="columns is-centered">
            <div class="column is-8">
              <div class="content">
                <p>
                  This website is licensed under a <a rel="license"
                    href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                    Commons Attribution-ShareAlike 4.0 International License</a>.
                </p>
                <p>
                  This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source
                    code</a> of this website,
                  we just ask that you link back to this page in the footer.
                  Please remember to remove the analytics code included in the header of the website which
                  you do not want on your website.
                </p>
              </div>
            </div>
          </div>
        </div>
      </footer>

</body>

</html>